{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./assets/agent-definition.jpeg\" alt=\"drawing\" style=\"width:1000px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understasnding LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./assets/question-received.jpeg\" alt=\"drawing\" style=\"width:1000px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./assets/tokenizer-schema.jpeg\" alt=\"drawing\" style=\"width:800px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding Space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./assets/ES1.png\" alt=\"drawing\" style=\"width:800px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./assets/ES2.png\" alt=\"drawing\" style=\"width:800px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention Mechanism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./assets/llm-schema.jpeg\" alt=\"drawing\" style=\"width:1000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./assets/Attention.png\" alt=\"drawing\" style=\"width:1000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why LLMs Hallucinate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./assets/Halluc.png\" alt=\"drawing\" style=\"width:1000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practical Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(X):\n",
    "   return 1/(1+np.exp(-X))\n",
    "class VanillaRNN():\n",
    "  def __init__(self,size=8):\n",
    "    # define size x size vector\n",
    "    self.size=size\n",
    "    self.memory_states=[]\n",
    "    self.weigths=np.zeros((size*size,size*size))\n",
    "\n",
    "  def set_memory_state(self,state):\n",
    "    self.memory_states.append(state)\n",
    "\n",
    "  def print_memory_states(self):\n",
    "    total_memory=len(self.memory_states)\n",
    "    fig, axs = plt.subplots(nrows=total_memory, ncols=1, figsize=(8, 6))\n",
    "    for ax, memory_state in zip(axs, self.memory_states):\n",
    "      vector_square=memory_state.reshape(self.size,self.size)\n",
    "      ax.imshow(vector_square, cmap='gray')\n",
    "    fig.show()\n",
    "\n",
    "  def hebbian_learning(self):\n",
    "    for m in self.memory_states:\n",
    "        print('State Learned')\n",
    "        m = np.where(m == 0, -1, m)\n",
    "        outer_product = np.outer(m, m)\n",
    "        np.fill_diagonal(outer_product, 0)\n",
    "\n",
    "        self.weigths += outer_product\n",
    "    self.weigths /= len(self.memory_states)\n",
    "\n",
    "  @staticmethod\n",
    "  def update_state(W, state):\n",
    "    size = state.size\n",
    "    new_state = state.copy()\n",
    "    for i in range(size):\n",
    "        weighted_sum = np.dot(W[i, :], state)\n",
    "        new_state[i] = 1 if weighted_sum > 0 else -1\n",
    "    return new_state\n",
    "\n",
    "  def recall(self,initial_state):\n",
    "    current_state = initial_state\n",
    "    i=0\n",
    "    while True:\n",
    "        i+=1\n",
    "        next_state = self.update_state(self.weigths, current_state)\n",
    "        if np.array_equal(next_state, current_state):\n",
    "            print('Convergence reached in',i,'iterations')\n",
    "            break  # Convergence reached\n",
    "        current_state = next_state\n",
    "    return current_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State Learned\n",
      "State Learned\n",
      "State Learned\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/db/hk4pr53504x2lk8kpgbxs6_c0000gn/T/ipykernel_4789/3911467420.py:19: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  fig.show()\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = VanillaRNN(10)\n",
    "a.set_memory_state(np.array([0,0,1,1,1,1,1,0,0,0,0,1,0,0,0,0,1,0,0,0,1,0,0,0,0,0,1,0,0,0,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,1,0,0,1,1,0,0,0,0,0,1,0,0,1,1,1,1,1,1,1,1,1,1,1,1,0,0,1,0,0,0,0,0,1,1,0,0,1,0,0,0,0,1,0,1,1,1,1,1,1,1,1,0,0]))\n",
    "a.set_memory_state(np.array([1,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0,1,0,0,0,1,0,0,0,0,1,0,0,0,0,0,1,0,0,1,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,1,0,0,1,0,0,0,0,0,1,0,0,0,0,1,0,0,0,1,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0,0,0,1]))\n",
    "a.set_memory_state(np.array([0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,0,0,1,0,0,0,0,0,0,1,0,0,1,0,1,1,1,1,0,1,0,0,1,0,1,0,0,1,0,1,0,0,1,0,1,0,0,1,0,1,0,0,1,0,1,1,1,1,0,1,0,0,1,0,0,0,0,0,0,1,0,0,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0]))\n",
    "a.hebbian_learning()\n",
    "a.print_memory_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAGdCAYAAAAv9mXmAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAAATWUlEQVR4nO3df6jV9f3A8de513nvLe49qE1LvKb1x8wf/bwqJTRGUoSLNUbbwMAZ7I9xK50w0kWT4cwcLIRsprLZRmYNRusHOBDHdK5Cy2zFtgwG26XQCuKcMnaLez/fP/bd3S6Zu0fv655z9PGA9x9++nzu58UnOU8+53M9p1QURREAMMpa6j0AAGcngQEghcAAkEJgAEghMACkEBgAUggMACkEBoAU48b6hIODg/H2229HZ2dnlEqlsT49AGegKIr44IMPYurUqdHScup7lDEPzNtvvx3d3d1jfVoARlFfX19MmzbtlPuMeWA6Ozsj4l/DdXV1jfXpP1O5XK73CAAnValU6j3CkGq1Gt3d3UOv5acy5oH599tiXV1dDRUYgEbViK+VI3nE4SE/ACkEBoAUAgNACoEBIIXAAJBCYABIITAApBAYAFIIDAApBAaAFAIDQIrTCszDDz8cM2bMiPb29li4cGEcPHhwtOcCoMnVHJgnn3wyVq1aFWvXro3Dhw/HFVdcETfddFO88847GfMB0KRqDsyDDz4Y3/72t2P58uUxe/bseOSRR+K8886Ln//85xnzAdCkagrMxx9/HC+//HIsXrz4Pz+gpSUWL14cL7zwwkmP6e/vj2q1OmwBcParKTDvvfdeDAwMxJQpU4ZtnzJlShw7duykx2zYsCHK5fLQ8m2WAOeG9N8iW7NmTVQqlaHV19eXfUoAGkBN32h5wQUXRGtraxw/fnzY9uPHj8eFF1540mPa2tqira3t9CcEoCnVdAczfvz4uOaaa2Lv3r1D2wYHB2Pv3r1x7bXXjvpwADSvmu5gIiJWrVoVy5Yti56enliwYEFs2rQpTpw4EcuXL8+YD4AmVXNgvvGNb8S7774bP/jBD+LYsWNx5ZVXxm9/+9tPPfgH4NxWKoqiGMsTVqvVKJfLUalUoqurayxPfUqlUqneIwCc1Bi/TJ9SLa/hPosMgBQCA0AKgQEghcAAkEJgAEghMACkEBgAUggMACkEBoAUAgNACoEBIEXNH3Y5Wsrlcr1OfVKN9Fk//+bz0WDseS0YPe5gAEghMACkEBgAUggMACkEBoAUAgNACoEBIIXAAJBCYABIITAApBAYAFIIDAApBAaAFAIDQAqBASCFwACQQmAASCEwAKQQGABSCAwAKQQGgBQCA0AKgQEghcAAkEJgAEghMACkEBgAUggMACkEBoAUAgNACoEBIIXAAJBCYABIITAApBAYAFIIDAApxtV7gEZRKpXqPQKcc4qiqPcIn+K1YPS4gwEghcAAkEJgAEghMACkEBgAUggMACkEBoAUAgNACoEBIIXAAJBCYABIITAApBAYAFIIDAApagrMhg0bYv78+dHZ2RmTJ0+OW2+9Nd54442s2QBoYjUFZt++fdHb2xsvvvhi7NmzJz755JO48cYb48SJE1nzAdCkSsUZfOPPu+++G5MnT459+/bF9ddfP6JjqtVqlMvl0z0lcBbxhWPNq1KpRFdX1yn3OaNvtKxUKhERMXHixM/cp7+/P/r7+4f+XK1Wz+SUADSJ037IPzg4GCtXroxFixbF3LlzP3O/DRs2RLlcHlrd3d2ne0oAmshpv0X2ne98J3bv3h0HDhyIadOmfeZ+J7uDERkgwltkzSztLbI777wznnvuudi/f/8p4xIR0dbWFm1tbadzGgCaWE2BKYoi7rrrrnjqqafi97//fcycOTNrLgCaXE2B6e3tjccffzyefvrp6OzsjGPHjkVERLlcjo6OjpQBAWhONT2D+az3Jnfs2BHf+ta3RvQz/Joy8G+ewTSvUX8G04h/GQBoTD6LDIAUAgNACoEBIIXAAJBCYABIITAApBAYAFIIDAApBAaAFAIDQAqBASDFGX1lMtA8GvGzBH2w5NnNHQwAKQQGgBQCA0AKgQEghcAAkEJgAEghMACkEBgAUggMACkEBoAUAgNACoEBIIXAAJBCYABIITAApBAYAFIIDAApBAaAFAIDQAqBASCFwACQQmAASCEwAKQQGABSCAwAKQQGgBQCA0AKgQEghcAAkEJgAEghMACkEBgAUggMACkEBoAUAgNACoEBIMW4eg8AjI1SqVTvETjHuIMBIIXAAJBCYABIITAApBAYAFIIDAApBAaAFAIDQAqBASCFwACQQmAASCEwAKQQGABSCAwAKc4oMA888ECUSqVYuXLlKI0DwNnitANz6NCh2Lp1a1x++eWjOQ8AZ4nTCsyHH34YS5cuje3bt8eECRNGeyYAzgKnFZje3t5YsmRJLF68+H/u29/fH9VqddgC4OxX81cmP/HEE3H48OE4dOjQiPbfsGFD/PCHP6x5MACaW013MH19fbFixYrYuXNntLe3j+iYNWvWRKVSGVp9fX2nNSgAzaVUFEUx0p1/85vfxFe/+tVobW0d2jYwMBClUilaWlqiv79/2H87mWq1GuVy+fQnBqDuKpVKdHV1nXKfmt4iu+GGG+K1114btm358uUxa9asuOeee/5nXAA4d9QUmM7Ozpg7d+6wbeeff35MmjTpU9sBOLf5l/wApKjpGcxo8AwGoPmN5BmMOxgAUggMACkEBoAUAgNACoEBIIXAAJBCYABIITAApBAYAFIIDAApBAaAFAIDQAqBASCFwACQQmAASCEwAKQQGABSCAwAKQQGgBQCA0AKgQEghcAAkEJgAEghMACkEBgAUggMACkEBoAUAgNACoEBIIXAAJBCYABIITAApBAYAFIIDAApBAaAFAIDQAqBASCFwACQQmAASCEwAKQQGABSCAwAKQQGgBQCA0AKgQEghcAAkEJgAEghMACkEBgAUggMACkEBoAUAgNACoEBIIXAAJBCYABIITAApBAYAFIIDAApBAaAFAIDQAqBASCFwACQQmAASFFzYN566624/fbbY9KkSdHR0RHz5s2Ll156KWM2AJrYuFp2fv/992PRokXxpS99KXbv3h2f//zn480334wJEyZkzQdAk6opMBs3bozu7u7YsWPH0LaZM2eO+lAANL+a3iJ75plnoqenJ2677baYPHlyXHXVVbF9+/ZTHtPf3x/VanXYAuAcUNSgra2taGtrK9asWVMcPny42Lp1a9He3l48+uijn3nM2rVri4iwLMuyzqJVqVT+ZzNKRVEUMULjx4+Pnp6eeP7554e23X333XHo0KF44YUXTnpMf39/9Pf3D/25Wq1Gd3f3SE8JQAOqVCrR1dV1yn1qeovsoosuitmzZw/bdtlll8U//vGPzzymra0turq6hi0Azn41BWbRokXxxhtvDNt29OjRuPjii0d1KADOArU8gzl48GAxbty4Yv369cWbb75Z7Ny5szjvvPOKxx57bMQ/o1Kp1P29Q8uyLOvM1kiewdQUmKIoimeffbaYO3du0dbWVsyaNavYtm1bTccLjGVZVvOvUX/IPxqq1WqUy+WxPCUAo2zUH/IDwEgJDAApBAaAFAIDQAqBASCFwACQQmAASCEwAKQQGABSCAwAKQQGgBQCA0AKgQEghcAAkEJgAEghMACkEBgAUggMACkEBoAUAgNACoEBIIXAAJBCYABIITAApBAYAFIIDAApBAaAFAIDQAqBASCFwACQQmAASCEwAKQQGABSCAwAKQQGgBQCA0AKgQEghcAAkEJgAEghMACkEBgAUggMACkEBoAUAgNACoEBIIXAAJBCYABIITAApBAYAFIIDAApBAaAFAIDQAqBASCFwACQQmAASCEwAKQQGABSCAwAKQQGgBQCA0AKgQEghcAAkEJgAEhRU2AGBgbivvvui5kzZ0ZHR0dceumlsW7duiiKIms+AJrUuFp23rhxY2zZsiV+8YtfxJw5c+Kll16K5cuXR7lcjrvvvjtrRgCaUE2Bef755+MrX/lKLFmyJCIiZsyYEbt27YqDBw+mDAdA86rpLbLrrrsu9u7dG0ePHo2IiFdffTUOHDgQN99882ce09/fH9VqddgC4BxQ1GBgYKC45557ilKpVIwbN64olUrF/ffff8pj1q5dW0SEZVmWdRatSqXyP5tRU2B27dpVTJs2rdi1a1fxpz/9qfjlL39ZTJw4sXj00Uc/85h//vOfRaVSGVp9fX11vzCWZVnWma1RD8y0adOKzZs3D9u2bt264gtf+MKIf0alUqn7hbEsy7LObI0kMDU9g/noo4+ipWX4Ia2trTE4OFjLjwHgHFDTb5HdcsstsX79+pg+fXrMmTMnXnnllXjwwQfjjjvuyJoPgGZVy1tk1Wq1WLFiRTF9+vSivb29uOSSS4p777236O/v9xaZZVnWObRG8hZZqSjG9p/hV6vVKJfLY3lKAEZZpVKJrq6uU+7js8gASCEwAKQQGABSCAwAKQQGgBQCA0AKgQEghcAAkEJgAEghMACkEBgAUggMACkEBoAUAgNACoEBIIXAAJBCYABIITAApBAYAFIIDAApBAaAFAIDQAqBASCFwACQQmAASCEwAKQQGABSCAwAKQQGgBQCA0AKgQEghcAAkEJgAEghMACkEBgAUggMACkEBoAUAgNACoEBIIXAAJBCYABIITAApBAYAFIIDAApBAaAFAIDQAqBASDFmAemKIqxPiUAo2wkr+VjHpgPPvhgrE8JwCgbyWt5qRjjW4rBwcF4++23o7OzM0ql0mn/nGq1Gt3d3dHX1xddXV2jOOHZxXUaGddpZFynkTmbr1NRFPHBBx/E1KlTo6Xl1Pco48ZopiEtLS0xbdq0Uft5XV1dZ93/wAyu08i4TiPjOo3M2XqdyuXyiPbzkB+AFAIDQIqmDUxbW1usXbs22tra6j1KQ3OdRsZ1GhnXaWRcp38Z84f8AJwbmvYOBoDGJjAApBAYAFIIDAApmjYwDz/8cMyYMSPa29tj4cKFcfDgwXqP1FA2bNgQ8+fPj87Ozpg8eXLceuut8cYbb9R7rIb2wAMPRKlUipUrV9Z7lIbz1ltvxe233x6TJk2Kjo6OmDdvXrz00kv1HquhDAwMxH333RczZ86Mjo6OuPTSS2PdunXn9OcvNmVgnnzyyVi1alWsXbs2Dh8+HFdccUXcdNNN8c4779R7tIaxb9++6O3tjRdffDH27NkTn3zySdx4441x4sSJeo/WkA4dOhRbt26Nyy+/vN6jNJz3338/Fi1aFJ/73Odi9+7d8ec//zl+8pOfxIQJE+o9WkPZuHFjbNmyJTZv3hx/+ctfYuPGjfHjH/84HnrooXqPVjdN+WvKCxcujPnz58fmzZsj4l+fb9bd3R133XVXrF69us7TNaZ33303Jk+eHPv27Yvrr7++3uM0lA8//DCuvvrq+OlPfxo/+tGP4sorr4xNmzbVe6yGsXr16vjjH/8Yf/jDH+o9SkP78pe/HFOmTImf/exnQ9u+9rWvRUdHRzz22GN1nKx+mu4O5uOPP46XX345Fi9ePLStpaUlFi9eHC+88EIdJ2tslUolIiImTpxY50kaT29vbyxZsmTY3yn+45lnnomenp647bbbYvLkyXHVVVfF9u3b6z1Ww7nuuuti7969cfTo0YiIePXVV+PAgQNx880313my+hnzD7s8U++9914MDAzElClThm2fMmVK/PWvf63TVI1tcHAwVq5cGYsWLYq5c+fWe5yG8sQTT8Thw4fj0KFD9R6lYf3tb3+LLVu2xKpVq+L73/9+HDp0KO6+++4YP358LFu2rN7jNYzVq1dHtVqNWbNmRWtrawwMDMT69etj6dKl9R6tbpouMNSut7c3Xn/99Thw4EC9R2kofX19sWLFitizZ0+0t7fXe5yGNTg4GD09PXH//fdHRMRVV10Vr7/+ejzyyCMC819+9atfxc6dO+Pxxx+POXPmxJEjR2LlypUxderUc/Y6NV1gLrjggmhtbY3jx48P2378+PG48MIL6zRV47rzzjvjueeei/3794/q1yScDV5++eV455134uqrrx7aNjAwEPv374/NmzdHf39/tLa21nHCxnDRRRfF7Nmzh2277LLL4te//nWdJmpM3/ve92L16tXxzW9+MyIi5s2bF3//+99jw4YN52xgmu4ZzPjx4+Oaa66JvXv3Dm0bHByMvXv3xrXXXlvHyRpLURRx5513xlNPPRW/+93vYubMmfUeqeHccMMN8dprr8WRI0eGVk9PTyxdujSOHDkiLv9v0aJFn/oV96NHj8bFF19cp4ka00cfffSpL+BqbW2NwcHBOk1Uf013BxMRsWrVqli2bFn09PTEggULYtOmTXHixIlYvnx5vUdrGL29vfH444/H008/HZ2dnXHs2LGI+NcXBXV0dNR5usbQ2dn5qWdS559/fkyaNMmzqv/y3e9+N6677rq4//774+tf/3ocPHgwtm3bFtu2bav3aA3llltuifXr18f06dNjzpw58corr8SDDz4Yd9xxR71Hq5+iST300EPF9OnTi/HjxxcLFiwoXnzxxXqP1FAi4qRrx44d9R6toX3xi18sVqxYUe8xGs6zzz5bzJ07t2hraytmzZpVbNu2rd4jNZxqtVqsWLGimD59etHe3l5ccsklxb333lv09/fXe7S6acp/BwNA42u6ZzAANAeBASCFwACQQmAASCEwAKQQGABSCAwAKQQGgBQCA0AKgQEghcAAkEJgAEjxfxQG2YH83JNdAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convergence reached in 2 iterations\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Teste de Memoria\n",
    "starting_state=np.array(\n",
    "[1,0,0,0,0,0,0,0,0,1\n",
    ",0,1,0,0,0,0,0,0,1,0\n",
    ",0,0,0,0,0,0,0,1,0,0\n",
    ",0,0,0,0,0,0,1,0,0,0\n",
    ",0,0,0,0,0,0,0,0,0,0\n",
    ",0,0,0,0,0,0,0,0,0,0\n",
    ",0,0,0,0,0,0,0,0,0,0\n",
    ",0,0,0,0,0,0,0,0,0,0\n",
    ",0,0,0,0,0,0,0,0,0,0\n",
    ",0,0,0,0,0,0,0,0,0,0])\n",
    "vector_square=starting_state.reshape(10,10)\n",
    "plt.imshow(vector_square,cmap='gray')\n",
    "plt.show()\n",
    "stt=a.recall(starting_state)\n",
    "vector_square=stt.reshape(10,10)\n",
    "plt.imshow(vector_square,cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convergence reached in 2 iterations\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Teste de Memoria\n",
    "starting_state=np.array(\n",
    "[0,0,1,0,0,0,0,0,0,1\n",
    ",0,1,0,0,0,0,0,0,1,0\n",
    ",1,0,0,0,0,0,0,1,0,0\n",
    ",1,1,1,1,1,1,1,0,0,0\n",
    ",0,0,0,0,0,0,0,0,0,0\n",
    ",0,0,0,0,0,0,0,0,0,0\n",
    ",0,0,0,0,0,0,0,0,0,0\n",
    ",0,0,0,0,0,0,0,0,0,0\n",
    ",0,0,0,0,0,0,0,0,0,0\n",
    ",0,0,0,0,0,0,0,0,0,0])\n",
    "vector_square=starting_state.reshape(10,10)\n",
    "plt.imshow(vector_square,cmap='gray')\n",
    "plt.show()\n",
    "stt=a.recall(starting_state)\n",
    "vector_square=stt.reshape(10,10)\n",
    "plt.imshow(vector_square,cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convergence reached in 3 iterations\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Teste de Memoria\n",
    "starting_state=np.array(\n",
    "[0,0,1,0,0,0,0,0,0,1\n",
    ",0,1,0,0,0,0,0,0,1,0\n",
    ",1,0,0,0,0,0,0,1,0,0\n",
    ",1,1,1,1,1,1,1,0,0,0\n",
    ",0,0,0,0,0,1,0,0,0,0\n",
    ",0,0,0,0,1,0,0,0,0,0\n",
    ",0,0,0,1,0,0,0,0,0,0\n",
    ",0,0,1,0,0,0,0,0,0,0\n",
    ",0,1,0,0,0,0,1,1,1,1\n",
    ",0,0,0,0,0,0,0,0,0,0])\n",
    "vector_square=starting_state.reshape(10,10)\n",
    "plt.imshow(vector_square,cmap='gray')\n",
    "plt.show()\n",
    "stt=a.recall(starting_state)\n",
    "vector_square=stt.reshape(10,10)\n",
    "plt.imshow(vector_square,cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./assets/agent-tools.jpeg\" alt=\"drawing\" style=\"width:1000px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Langchain Components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./assets/langchain-components.jpeg\" alt=\"drawing\" style=\"width:800px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installing dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pandas pydantic\n",
    "# pip install langchain langchain_core langchain_openai langchain_community langgraph\n",
    "# pip install bigquery google db-types\n",
    "# pip install wikipedia serpapi google-search-results numexpr\n",
    "# pip install PyPDF2 python-docx "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading ENV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading the environment\n",
    "import os\n",
    "\n",
    "os.getenv('./env')\n",
    "\n",
    "openAiApiKey = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Referencing the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "light_model = ChatOpenAI(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    temperature=0,\n",
    "    verbose=True\n",
    "  )\n",
    "\n",
    "powerful_model = ChatOpenAI(\n",
    "    model=\"gpt-4-turbo-2024-04-09\",\n",
    "    temperature=0,\n",
    "    verbose=True\n",
    "  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Braslia', response_metadata={'token_usage': {'completion_tokens': 3, 'prompt_tokens': 14, 'total_tokens': 17}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_c2295e73ad', 'finish_reason': 'stop', 'logprobs': None})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "light_model.invoke(\"What is the capital of Brazil?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In Rust, multithreading can be achieved using the `std::thread` module. Here is a basic example of how to create and run multiple threads in Rust:\\n\\n1. Import the necessary module:\\n```rust\\nuse std::thread;\\n```\\n\\n2. Define a function that will be executed by each thread:\\n```rust\\nfn thread_function(id: i32) {\\n    println!(\"Thread {} is running\", id);\\n}\\n```\\n\\n3. Create and run multiple threads:\\n```rust\\nfn main() {\\n    let mut handles = vec![];\\n\\n    for i in 0..5 {\\n        let handle = thread::spawn(move || {\\n            thread_function(i);\\n        });\\n        handles.push(handle);\\n    }\\n\\n    for handle in handles {\\n        handle.join().unwrap();\\n    }\\n}\\n```\\n\\nIn this example, we first define a function `thread_function` that takes an `i32` parameter and prints a message indicating the thread ID. Then, in the `main` function, we create a vector to store thread handles, iterate over a range of numbers to create multiple threads using `thread::spawn`, and push the handles to the vector. Finally, we wait for all threads to finish using `join`.\\n\\nRemember that Rust\\'s ownership system ensures that data races are prevented at compile time, making it easier to write safe multithreaded code.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"\"\"\n",
    "            You are a backend developer, and you are an expert in RUST.\n",
    "         \"\"\"),\n",
    "        (\"user\", \"\"\"\n",
    "        Answer this question as best as you can: {question}\n",
    "    \"\"\")]\n",
    ")\n",
    "\n",
    "parser = StrOutputParser()\n",
    "\n",
    "chain = (\n",
    "    prompt \n",
    "    | light_model \n",
    "    | parser\n",
    ")\n",
    "\n",
    "res = chain.invoke({\"question\": \"How to multithread in rust?\"})\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Memory Provider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "\n",
    "chat_history = ConversationBufferMemory(memory_key=\"chat_history\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Documentos Internos Brick (Normal Chunking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "main_page=requests.get('https://brickseguros.com.br')\n",
    "soup = BeautifulSoup(main_page.content, 'lxml')\n",
    "text=soup.get_text()\n",
    "links=[]\n",
    "for link in soup.find_all('a', href=True):\n",
    "    if 'http' in link['href'] and 'brickseguros.com.br' in link['href'] and 'mailto' not in link['href'] and link['href']!='https://brickseguros.com.br' :\n",
    "        links.append(link['href'])\n",
    "links=list(set(links))\n",
    "\n",
    "for link in links:\n",
    "    page=requests.get(link)\n",
    "    soup = BeautifulSoup(page.content, 'lxml')\n",
    "    text+=soup.get_text()\n",
    "\n",
    "brickdocuments=text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "\n",
    "with open('documents/brick_bs_cg.pdf', 'rb') as file:\n",
    "    reader = PyPDF2.PdfReader(file)\n",
    "    policy_conditions=''\n",
    "    for i in range(len(reader.pages)):\n",
    "        policy_conditions+=reader.pages[i].extract_text()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Circulares SUSEP (RAPTOR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "import io\n",
    "\n",
    "def get_susep_doc(url):\n",
    "    r=requests.get(url)\n",
    "    reader = PdfReader(io.BytesIO(r.content))\n",
    "    out_str=''\n",
    "    for i in range(len(reader.pages)):\n",
    "        out_str+=reader.pages[i].extract_text()\n",
    "    return out_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gov_doc(url):\n",
    "    r=requests.get(url)\n",
    "    # Parse the HTML content using BeautifulSoup\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "\n",
    "    # Find the div with class 'texto-dou'\n",
    "    target_div = soup.find('div', class_='texto-dou')\n",
    "\n",
    "    if target_div:\n",
    "        # Print the entire text content of the found div, including its children\n",
    "        return target_div.get_text()\n",
    "    else:\n",
    "        print(\"No div with class 'texto-dou' found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs=[]\n",
    "links_susep=[]\n",
    "links_gov=[]\n",
    "with open('documents/susep_links.txt') as f:\n",
    "    for line in f:\n",
    "        if line.startswith('https://www2.susep.gov.br'):\n",
    "            links_susep.append(line.strip())\n",
    "        else:\n",
    "            links_gov.append(line.strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "for item in tqdm(links_susep):\n",
    "    try:\n",
    "        docs.append(get_susep_doc(item))\n",
    "    except:\n",
    "        print('Error on',item)\n",
    "for item in tqdm(links_gov):\n",
    "    try:\n",
    "        docs.append(get_gov_doc(item))\n",
    "    except:\n",
    "        print('Error on',item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index,item in enumerate(docs):\n",
    "    with open(f'documents/raw_susep/{index}.txt','w') as f:\n",
    "        f.write(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraction to index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "susep_docs=[]\n",
    "for file in os.listdir('documents/raw_susep'):\n",
    "    with open(f'documents/raw_susep/{file}','r') as f:\n",
    "        susep_docs.append(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cdigo Civil (Multi Representation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('documents/codcivil.html','r',encoding='utf-8') as f:\n",
    "    soup = BeautifulSoup(f.read(), 'lxml')\n",
    "#get all elements inside mais soup\n",
    "elements = soup.find_all(recursive=False)[0].find_all(recursive=False)[0].find_all(recursive=False)\n",
    "textelements=[x.get_text().strip() for x in elements]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "livro=''\n",
    "titulo=''\n",
    "capitulo=''\n",
    "secao=''\n",
    "subsecao=''\n",
    "outstr=''\n",
    "lastwastext=False\n",
    "codigo_civill=[]\n",
    "for item in textelements:\n",
    "    if item.startswith('LIVRO'):\n",
    "        if lastwastext:\n",
    "            codigo_civill.append(outstr)\n",
    "        livro=item\n",
    "        titulo=''\n",
    "        capitulo=''\n",
    "        secao=''\n",
    "        subsecao=''\n",
    "        outstr=''\n",
    "        lastwastext=False\n",
    "    elif item.startswith('TTULO'):\n",
    "        if lastwastext:\n",
    "            codigo_civill.append(outstr)\n",
    "        titulo=item\n",
    "        capitulo=''\n",
    "        secao=''\n",
    "        subsecao=''\n",
    "        outstr=''\n",
    "        lastwastext=False\n",
    "    elif item.startswith('CAPTULO'):\n",
    "        if lastwastext:\n",
    "            codigo_civill.append(outstr)\n",
    "        capitulo=item\n",
    "        secao=''\n",
    "        subsecao=''\n",
    "        outstr=''\n",
    "        lastwastext=False\n",
    "    elif item.startswith('Seo'):\n",
    "        if lastwastext:\n",
    "            codigo_civill.append(outstr)\n",
    "        secao=item\n",
    "        subsecao=''\n",
    "        outstr=''\n",
    "        lastwastext=False\n",
    "    elif item.startswith('SUBSEO'):\n",
    "        if lastwastext:\n",
    "            codigo_civill.append(outstr)\n",
    "        subsecao=item\n",
    "        outstr=''\n",
    "        lastwastext=False\n",
    "    else:\n",
    "        if not lastwastext:\n",
    "            outstr+=f'{livro} - {titulo} - {capitulo} - {secao} - {subsecao}\\n'\n",
    "        lastwastext=True\n",
    "        outstr += item+'\\n'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500, \n",
    "    chunk_overlap=50, \n",
    "    separators=[\"#######\", \"\\n\", \"\\r\\n\", \"\\r\"],\n",
    ")\n",
    "\n",
    "texts = text_splitter.split_text(brickdocuments)\n",
    "documents = text_splitter.create_documents(texts)\n",
    "print(len(documents))\n",
    "db = Chroma.from_documents(documents, OpenAIEmbeddings(\n",
    "),collection_name='brick_general')\n",
    "\n",
    "brick_general_retriever = db.as_retriever(collection_name='brick_general')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320\n"
     ]
    }
   ],
   "source": [
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500, \n",
    "    chunk_overlap=50, \n",
    "    separators=[\"#######\", \"\\n\", \"\\r\\n\", \"\\r\"],\n",
    ")\n",
    "\n",
    "texts = text_splitter.split_text(policy_conditions)\n",
    "documents = text_splitter.create_documents(texts)\n",
    "print(len(documents))\n",
    "db2 = Chroma.from_documents(documents, OpenAIEmbeddings(\n",
    "),collection_name='insurance_brick')\n",
    "\n",
    "brick_insurance_retriever = db2.as_retriever(collection_name='insurance_brick')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SUSEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2125\n"
     ]
    }
   ],
   "source": [
    "texts='#####################################'.join(susep_docs)\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500, \n",
    "    chunk_overlap=50, \n",
    "    separators=[\"#######\", \"\\n\", \"\\r\\n\", \"\\r\"],\n",
    ")\n",
    "\n",
    "texts = text_splitter.split_text(texts)\n",
    "documents = text_splitter.create_documents(texts)\n",
    "print(len(documents))\n",
    "db = Chroma.from_documents(documents, OpenAIEmbeddings(\n",
    "),collection_name='susep')\n",
    "\n",
    "brick_susep_retriever = db.as_retriever(collection_name='susep')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cdigo civil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "import json\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "\n",
    "chain = (\n",
    "    {\"doc\": lambda x: x.page_content}\n",
    "    | ChatPromptTemplate.from_template(\"Summarize os seguintes documentos::\\n\\n{doc}\")\n",
    "    | light_model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "docs=[Document(x) for x in codigo_civill]\n",
    "summaries = chain.batch(docs, {\"max_concurrency\": 5})\n",
    "\n",
    "with open('cod_civil_summaries.json','w') as f:\n",
    "    json.dump(summaries, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Tokenized Civil Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load the summaries\n",
    "with open('cod_civil_summaries.json','r') as f:\n",
    "    summaries=json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.storage import InMemoryByteStore\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.retrievers.multi_vector import MultiVectorRetriever\n",
    "from langchain_core.documents import Document\n",
    "import uuid\n",
    "\n",
    "docs=[Document(x) for x in codigo_civill]\n",
    "# The vectorstore to use to index the child chunks\n",
    "vectorstore_cc = Chroma(collection_name=\"summaries\",\n",
    "                     embedding_function=OpenAIEmbeddings())\n",
    "\n",
    "# The storage layer for the parent documents\n",
    "store = InMemoryByteStore()\n",
    "id_key = \"doc_id\"\n",
    "\n",
    "# The retriever\n",
    "retriever_cc = MultiVectorRetriever(\n",
    "    vectorstore=vectorstore_cc,\n",
    "    byte_store=store,\n",
    "    id_key=id_key,\n",
    "    search_kwargs={\"k\": 3}\n",
    "\n",
    ")\n",
    "doc_ids = [str(uuid.uuid4()) for _ in docs]\n",
    "\n",
    "# Docs linked to summaries\n",
    "summary_docs = [\n",
    "    Document(page_content=s, metadata={id_key: doc_ids[i]})\n",
    "    for i, s in enumerate(summaries)\n",
    "]\n",
    "\n",
    "# Add\n",
    "retriever_cc.vectorstore.add_documents(summary_docs)\n",
    "retriever_cc.docstore.mset(list(zip(doc_ids, docs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': '\\nLocadora XPTY - Forms\\n\\nFormulrio para Cadastro de motoristas do vendedor Guilherme \\n\\nCor: #00FF00\\nEntidade: PF',\n",
       " 'error': None,\n",
       " 'file': './files/inputs.txt'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.tools import tool\n",
    "import PyPDF2\n",
    "import docx\n",
    "import json\n",
    "\n",
    "@tool\n",
    "def read_txt_file(file: str):\n",
    "    \"\"\"\n",
    "        This tool reads a text file and returns its content.\n",
    "        It receives the file path as input.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file, 'r') as f:\n",
    "            return {\n",
    "                \"content\": f.read(),\n",
    "                \"error\": None,\n",
    "                \"file\": file\n",
    "            }\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"content\": None,\n",
    "            \"error\": str(e),\n",
    "            \"file\": file\n",
    "        }\n",
    "\n",
    "@tool\n",
    "def read_docx_file(file):\n",
    "    \"\"\"\n",
    "        This tool reads a docx file and returns its content.\n",
    "        It receives the file path as input.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        doc = docx.Document(file)\n",
    "        fullText = []\n",
    "        for para in doc.paragraphs:\n",
    "            fullText.append(para.text)\n",
    "        return {\n",
    "            \"content\": '\\n'.join(fullText),\n",
    "            \"error\": None,\n",
    "            \"file\": file\n",
    "        }\n",
    "        # return {\n",
    "        #     \"content\": \"NOT SUPORTED YET!\",\n",
    "        #     \"error\": None,\n",
    "        #     \"file\": file\n",
    "        # }\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"content\": None,\n",
    "            \"error\": str(e),\n",
    "            \"file\": file\n",
    "        }\n",
    "\n",
    "@tool\n",
    "def read_pdf_file(file):\n",
    "    \"\"\"\n",
    "        This tool reads a pdf file and returns its content.\n",
    "        It receives the file path as input.\n",
    "    \"\"\"\n",
    "\n",
    "    try :\n",
    "        with open(file, 'rb') as f:\n",
    "            pdf = PyPDF2.PdfReader(f)\n",
    "            fullText = []\n",
    "            for page_num in range(len(pdf.pages)):\n",
    "                page = pdf.pages[page_num]\n",
    "                fullText.append(page.extract_text())\n",
    "            return {\n",
    "                \"content\": '\\n'.join(fullText),\n",
    "                \"error\": None,\n",
    "                \"file\": file\n",
    "            }\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"content\": None,\n",
    "            \"error\": str(e),\n",
    "            \"file\": file\n",
    "        }\n",
    "@tool\n",
    "def read_md_file(file):\n",
    "    \"\"\"\n",
    "        This tool reads a markdown file and returns its content.\n",
    "        It receives the file path as input.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        with open(file, 'r') as f:\n",
    "            return {\n",
    "                \"content\": f.read(),\n",
    "                \"error\": None,\n",
    "                \"file\": file\n",
    "            }\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"content\": None,\n",
    "            \"error\": str(e),\n",
    "            \"file\": file\n",
    "        }\n",
    "    \n",
    "@tool \n",
    "def read_html_file(file):\n",
    "    \"\"\"\n",
    "        This tool reads a html file and returns its content.\n",
    "        It receives the file path as input.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        with open(file, 'r') as f:\n",
    "            return {\n",
    "                \"content\": f.read(),\n",
    "                \"error\": None,\n",
    "                \"file\": file\n",
    "            }\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"content\": None,\n",
    "            \"error\": str(e),\n",
    "            \"file\": file\n",
    "        }\n",
    "    \n",
    "@tool\n",
    "def read_json_file(file):\n",
    "    \"\"\"\n",
    "        This tool reads a json file and returns its content.\n",
    "        It receives the file path as input.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        with open(file, 'r') as f:\n",
    "            return {\n",
    "                \"content\": json.load(f),\n",
    "                \"error\": None,\n",
    "                \"file\": file\n",
    "            }\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"content\": None,\n",
    "            \"error\": str(e),\n",
    "            \"file\": file\n",
    "        }\n",
    "    \n",
    "read_txt_file('./files/inputs.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chart Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from typing import List\n",
    "import matplotlib.pyplot as plt\n",
    "      \n",
    "@tool\n",
    "def plot_bar_chart(\n",
    "      labels: List,\n",
    "      values: List,\n",
    "      title: str,\n",
    "      x_label: str,\n",
    "      y_label: str\n",
    "):\n",
    "      \"\"\"\n",
    "            This tool plots a bar chart. \n",
    "          \n",
    "      \"\"\"\n",
    "      try:\n",
    "\n",
    "            if (labels is None):\n",
    "                  return {\n",
    "                        \"message\": \"O campo labels no pode ser nulo. Envie em um formato vlido.\"\n",
    "                  }\n",
    "\n",
    "            if(values is None):\n",
    "                  return {\n",
    "                        \"message\": \"O campo values no pode ser nulo. Envie em um formato vlido.\"\n",
    "                  }\n",
    "            \n",
    "\n",
    "            # Plotting the bar chart\n",
    "            plt.bar(labels, values)\n",
    "            plt.xlabel(x_label)\n",
    "            plt.ylabel(y_label)\n",
    "            plt.title(title)\n",
    "            plt.show()\n",
    "      except Exception as error:\n",
    "        return {\n",
    "             \"message\": \"Tente formatar novamente os dados\",\n",
    "            \"error\": error\n",
    "        }\n",
    "      \n",
    "\n",
    "@tool\n",
    "def plot_line_chart(\n",
    "      labels: List,\n",
    "      values: List,\n",
    "      title: str,\n",
    "      x_label: str,\n",
    "      y_label: str\n",
    "):\n",
    "      \"\"\"\n",
    "            This tool plots a line chart. \n",
    "          \n",
    "      \"\"\"\n",
    "      try:\n",
    "\n",
    "            if (labels is None):\n",
    "                  return {\n",
    "                        \"message\": \"O campo labels no pode ser nulo. Envie em um formato vlido.\"\n",
    "                  }\n",
    "\n",
    "            if(values is None):\n",
    "                  return {\n",
    "                        \"message\": \"O campo values no pode ser nulo. Envie em um formato vlido.\"\n",
    "                  }\n",
    "            \n",
    "\n",
    "            # Plotting the line chart\n",
    "            plt.plot(labels, values)\n",
    "            plt.xlabel(x_label)\n",
    "            plt.ylabel(y_label)\n",
    "            plt.title(title)\n",
    "            plt.show()\n",
    "      except Exception as error:\n",
    "        return {\n",
    "             \"message\": \"Tente formatar novamente os dados\",\n",
    "            \"error\": error\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brick Related Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RAG - Retrieval-Augmented Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./assets/basic-rag.jpeg\" alt=\"drawing\" style=\"width:800px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt\n",
    "brick_internal_rag_prompt = \"\"\"\n",
    "        Your name is Brick AI.\n",
    "        You work for a company called Brick Seguros - it helps fleet operators to manage thir risks.\n",
    "        You are here to help the user with his questions.\n",
    "        You are an expert in the field of fleets.\n",
    "        Answer the user's question as best as you can based on the context below.\n",
    "        Be concise and clear. Be direct and to the point.\n",
    "        Question: {question}\n",
    "        Context: {context}\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Saiba Mais\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nEstamos construindo o ecossistema de segurana para frotas, tijolo por tijolo.  \\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nFaa parte do nosso ecossistema \\n\\n\\n\\n \\n\\n \\n\\n \\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nO que falam da Brick na  mdia \\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\nEmpresas que usam Brick'),\n",
       " Document(page_content='Entre em contato com um de nossos especialistas e descubra como a Brick pode fazer a diferena na sua locadora.\\n\\nQuero conhecer o ecossistema Brick\\n\\n\\n\\n\\n\\n\\nDeixe um comentrio Cancelar respostaO seu endereo de e-mail no ser publicado. Campos obrigatrios so marcados com *Comentrio * Nome * \\nE-mail * \\nSite \\n Salvar meus dados neste navegador para a prxima vez que eu comentar.\\n \\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n \\n\\n\\nInstagram\\n \\n\\n\\n\\nLinkedin\\n \\n\\n\\n\\nWhatsapp\\n \\n\\n\\n\\n\\n\\n\\n\\n\\nContato'),\n",
       " Document(page_content='Quero conhecer o ecossistema Brick\\n\\n\\n\\n\\n\\n\\nDeixe um comentrio Cancelar respostaO seu endereo de e-mail no ser publicado. Campos obrigatrios so marcados com *Comentrio * Nome * \\nE-mail * \\nSite \\n Salvar meus dados neste navegador para a prxima vez que eu comentar.\\n \\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n \\n\\n\\nInstagram\\n \\n\\n\\n\\nLinkedin\\n \\n\\n\\n\\nWhatsapp\\n \\n\\n\\n\\n\\n\\n\\n\\n\\nContato \\n\\n\\n\\n\\n\\n\\n\\n \\nAv. Sete de Setembro, 2451 - Rebouas, Curitiba - PR, 80230-010\\n\\n\\n\\n\\n\\n \\ncontato@brickseguros.com.br\\n\\n\\n\\n\\n\\n \\n(41) 9 9263-9123'),\n",
       " Document(page_content='Inicie agora mesmo a construo de um ecossistema de segurana na sua locadora\\nNossos produtos so flexveis e modulares, permitindo que voc escolha quais, como e onde usar. Quanto maior a rede de locadoras parceiras da Brick, maior nosso potencial de segurana para todo o nicho.\\nEntre em contato com um de nossos especialistas e descubra como a Brick pode fazer a diferena na sua locadora.\\n\\nQuero conhecer o ecossistema Brick')]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from operator import itemgetter\n",
    "\n",
    "# Chain\n",
    "def brick_internal_chain(question):\n",
    "\n",
    "    parser = StrOutputParser()\n",
    "    prompt = ChatPromptTemplate.from_template(brick_internal_rag_prompt)\n",
    "    chain = (\n",
    "        {\"context\": itemgetter(\"question\") | brick_general_retriever, \"question\": itemgetter(\"question\")} |\n",
    "        prompt |\n",
    "        light_model |\n",
    "        parser\n",
    "    )\n",
    "\n",
    "    result = chain.invoke({\n",
    "        \"question\": question\n",
    "    })\n",
    "\n",
    "    return result\n",
    "\n",
    "# brick_internal_chain('Quais os produtos da Brick?')\n",
    "brick_general_retriever.invoke(\"Quais os produtos da Brick?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def brick_internal_rag_tool(\n",
    "    question: str\n",
    "):\n",
    "    \"\"\"\n",
    "        This tool retrieves answers for a questions about Brick Seguros.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        return brick_internal_chain(question)\n",
    "    except Exception as error:\n",
    "        return str(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insurance Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RAG at Scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./assets/rag-schema.jpeg\" alt=\"drawing\" style=\"width:800px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Routing or Adaptive RAG**\n",
    "- Semantic Routing\n",
    "\n",
    "https://arxiv.org/abs/2403.14403\n",
    "\n",
    "**Query Translation**\n",
    "- RAG-Fusion\n",
    "\n",
    "https://towardsdatascience.com/forget-rag-the-future-is-rag-fusion-1147298d8ad1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./assets/insurance-graph.jpeg\" alt=\"drawing\" style=\"width:600px;\"/>\n",
    "<img src=\"./assets/rag-fusion.jpeg\" alt=\"drawing\" style=\"width:600px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating the state\n",
    "\n",
    "from pydantic import BaseModel\n",
    "from typing import List, Optional, TypedDict\n",
    "\n",
    "## Defining the graph state\n",
    "class InsuranceQuestionGraphState(TypedDict):\n",
    "    # Input\n",
    "    question: str\n",
    "\n",
    "    # Internal\n",
    "    errors: Optional[List[str]] = []\n",
    "\n",
    "    # Output\n",
    "    result: Optional[str] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Defining the routing node\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "def routing_node(state):\n",
    "    insurance_routing_message = \"\"\"\n",
    "        You are an expert at routing a user question.\n",
    "        You work for a company called Brick Seguros - it helps fleet operators to manage their risks.\n",
    "        You are very knowledgeable about the field of insurance.\n",
    "        You are a specialist in identifying if the question is related to Brick insurance product or to general insurance legislation.\n",
    "        Answer the user's question with a json response.\n",
    "        ----\n",
    "        Json structure:\n",
    "            - result: boolean (true if the question is related to Brick insurance product, false if it is related to general insurance legislation)\n",
    "        ----\n",
    "        Question: {question}\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_template(insurance_routing_message)\n",
    "\n",
    "    question_router = prompt | light_model | JsonOutputParser()\n",
    "\n",
    "    router = question_router.invoke({\"question\": state[\"question\"]})\n",
    "\n",
    "    if router[\"result\"]:\n",
    "        return \"brick\"\n",
    "    else:\n",
    "        return \"general\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.load import dumps, loads\n",
    "\n",
    "def reciprocal_rank_fusion(results: list[list], k=60):\n",
    "    \"\"\" Reciprocal_rank_fusion that takes multiple lists of ranked documents \n",
    "        and an optional parameter k used in the RRF formula \"\"\"\n",
    "    \n",
    "    # Initialize a dictionary to hold fused scores for each unique document\n",
    "    fused_scores = {}\n",
    "\n",
    "    # Iterate through each list of ranked documents\n",
    "    for docs in results:\n",
    "        # Iterate through each document in the list, with its rank (position in the list)\n",
    "        for rank, doc in enumerate(docs):\n",
    "            # Convert the document to a string format to use as a key (assumes documents can be serialized to JSON)\n",
    "            doc_str = dumps(doc)\n",
    "            # If the document is not yet in the fused_scores dictionary, add it with an initial score of 0\n",
    "            if doc_str not in fused_scores:\n",
    "                fused_scores[doc_str] = 0\n",
    "            # Retrieve the current score of the document, if any\n",
    "            previous_score = fused_scores[doc_str]\n",
    "            # Update the score of the document using the RRF formula: 1 / (rank + k)\n",
    "            fused_scores[doc_str] += 1 / (rank + k)\n",
    "\n",
    "    # Sort the documents based on their fused scores in descending order to get the final reranked results\n",
    "    reranked_results = [\n",
    "        (loads(doc), score)\n",
    "        for doc, score in sorted(fused_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    ]\n",
    "\n",
    "    # Return the reranked results as a list of tuples, each containing the document and its fused score\n",
    "    return reranked_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Defining the brick node\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from operator import itemgetter\n",
    "\n",
    "\n",
    "def brick_node(state):\n",
    "    # RAG-Fusion template\n",
    "    rag_fusion_template = \"\"\"You are a helpful assistant that generates multiple search queries based on a single input query. \\n\n",
    "    You work for a company called Brick Seguros - it helps fleet operators to manage their risks.\n",
    "    Generate multiple search queries related to: {question} \\n\n",
    "    Remember to be concise and clear. Be direct and to the point. \\n\n",
    "    Remember that they should be related to Brick Seguros Insurance product.\n",
    "    Output (3 queries):\"\"\"\n",
    "    prompt_rag_fusion = ChatPromptTemplate.from_template(rag_fusion_template)\n",
    "\n",
    "    custom_parser = StrOutputParser() | (lambda x: x.split(\"\\n\"))\n",
    "\n",
    "    generate_queries = (\n",
    "        prompt_rag_fusion \n",
    "        | light_model\n",
    "        | custom_parser ### This is a custom function that splits the output by new lines\n",
    "    )\n",
    "\n",
    "    retrieval_chain_rag_fusion = generate_queries | brick_insurance_retriever.map() | reciprocal_rank_fusion\n",
    "\n",
    "    brick_insurance_product_template = \"\"\"\n",
    "    Your name is Brick AI. \\n\n",
    "    You work for a company called Brick Seguros - it helps fleet operators to manage thir risks. \\n\n",
    "    You are here to help the user with his questions. \\n\n",
    "    You are an expert in the field of fleets. \\n\n",
    "    Answer the user's question as best as you can based on the context below. \\n\n",
    "    Be concise and clear. Be direct and to the point. \\n\n",
    "    Context: {context}\n",
    "    Question: {question}\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_template(brick_insurance_product_template)\n",
    "\n",
    "    final_rag_chain = (\n",
    "        {\"context\": retrieval_chain_rag_fusion, \n",
    "        \"question\": itemgetter(\"question\")} \n",
    "        | prompt\n",
    "        | light_model\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "    res = final_rag_chain.invoke({\"question\": state[\"question\"] })\n",
    "\n",
    "    return  {\n",
    "        \"result\": res,\n",
    "        \"errors\": None,\n",
    "        \"question\": state[\"question\"]\n",
    "    }\n",
    "\n",
    "brick_node(InsuranceQuestionGraphState(question=\"Quais as coberturas do seu produto de seguro?\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Defining the general node\n",
    "\n",
    "def general_node(state):\n",
    "    # RAG-Fusion template\n",
    "    rag_fusion_susep_template = \"\"\"You are a helpful assistant that generates multiple search queries based on a single input query. \\n\n",
    "    You work for a company called Brick Seguros - it helps fleet operators to manage their risks.\n",
    "    Generate multiple search queries related to: {question} \\n\n",
    "    Remember to be concise and clear. Be direct and to the point. \\n\n",
    "    Remember that they should be related to general insurance legislation.\n",
    "    Output (3 queries):\"\"\"\n",
    "    prompt_general_rf_template = ChatPromptTemplate.from_template(rag_fusion_susep_template)\n",
    "\n",
    "    custom_parser = StrOutputParser() | (lambda x: x.split(\"\\n\"))\n",
    "\n",
    "    susep_generate_queries = (\n",
    "        prompt_general_rf_template \n",
    "        | light_model\n",
    "        | custom_parser ### This is a custom function that splits the output by new lines\n",
    "    )\n",
    "\n",
    "    susep_chain = susep_generate_queries | brick_susep_retriever.map() | reciprocal_rank_fusion\n",
    "\n",
    "    susep_template = \"\"\"\n",
    "    Your name is Brick AI. \\n\n",
    "    You work for a company called Brick Seguros - it helps fleet operators to manage thir risks. \\n\n",
    "    You are here to help the user with his questions. \\n\n",
    "    You are an expert in the field of fleets. \\n\n",
    "    Answer the user's question as best as you can based on the context below. \\n\n",
    "    Be concise and clear. Be direct and to the point. \\n\n",
    "    Context: {context}\n",
    "    Question: {question}\n",
    "    \"\"\"\n",
    "\n",
    "    susep_prompt = ChatPromptTemplate.from_template(susep_template)\n",
    "\n",
    "    susep_rag_chain = (\n",
    "        {\n",
    "            \"context\": susep_chain, \n",
    "            \"question\": itemgetter(\"question\")\n",
    "        } \n",
    "        | susep_prompt\n",
    "        | light_model\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "    res = susep_rag_chain.invoke({\"question\": state[\"question\"] })\n",
    "\n",
    "    return  {\n",
    "        \"result\": res,\n",
    "        \"errors\": None,\n",
    "        \"question\": state[\"question\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "### Defining the graph\n",
    "\n",
    "from langgraph.graph import END, StateGraph\n",
    "\n",
    "insurance_question_graph = StateGraph(InsuranceQuestionGraphState)\n",
    "\n",
    "insurance_question_graph.add_node(\"brick_node\", brick_node)\n",
    "insurance_question_graph.add_node(\"general_node\", general_node)\n",
    "\n",
    "insurance_question_graph.set_conditional_entry_point(\n",
    "    routing_node, \n",
    "    {\n",
    "        \"brick\": \"brick_node\",\n",
    "        \"general\": \"general_node\"\n",
    "    }\n",
    ")\n",
    "\n",
    "insurance_question_graph.add_edge(\"brick_node\", END)\n",
    "\n",
    "insurance_question_graph.add_edge(\"general_node\", END)\n",
    "\n",
    "insurance_question_graph_runnable = insurance_question_graph.compile()\n",
    "\n",
    "Image(insurance_question_graph_runnable.get_graph().draw_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Creating the tool\n",
    "\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def insurance_question_tool(\n",
    "    question: str\n",
    "):\n",
    "    \"\"\"\n",
    "        This tool retrieves answers for a questions about Insurance.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        return insurance_question_graph_runnable.invoke({\n",
    "            \"question\": question\n",
    "        })\n",
    "    except Exception as error:\n",
    "        return str(error)\n",
    "\n",
    "insurance_question_tool(\"Quais as coberturas do seu produto de seguro?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Civil Code Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieval and Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./assets/rag-schema.jpeg\" alt=\"drawing\" style=\"width:800px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**CRAG**\n",
    "- Corrective RAG (Fallback)\n",
    "\n",
    "https://arxiv.org/pdf/2401.15884.pdf\n",
    "\n",
    "**Self-RAG**\n",
    "- Self Correction and Self Reflection\n",
    "\n",
    "https://arxiv.org/abs/2310.11511"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./assets/self-crag.jpeg\" alt=\"drawing\" style=\"width:800px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create state\n",
    "\n",
    "from pydantic import BaseModel\n",
    "from typing import List, Optional, TypedDict\n",
    "\n",
    "class CivilCodeSearchGraphState(TypedDict):\n",
    "    # Input\n",
    "    question : str\n",
    "\n",
    "    # Internal\n",
    "    web_search : bool = False\n",
    "    documents : Optional[List[str]] = []\n",
    "\n",
    "    # Output\n",
    "    generation: Optional[str] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Defining the routing node\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "def civil_code_routing_node(state):\n",
    "    civil_code_routing_message = \"\"\"\n",
    "        You are an expert at routing a user question.\n",
    "        You work for a company called Brick Seguros - it helps fleet operators to manage their risks.\n",
    "        You are very knowledgeable about the brazilian civil code.\n",
    "        You are a specialist in identifying if the question is related to the brazilian civil code or not.\n",
    "        Answer the user's question with a json response.\n",
    "        ----\n",
    "        Json structure:\n",
    "            - result: boolean (true if the question is related to Brazilian civil code, false if it is not)\n",
    "        ----\n",
    "        Question: {question}\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_template(civil_code_routing_message)\n",
    "\n",
    "    question_router = prompt | light_model | JsonOutputParser()\n",
    "\n",
    "    router = question_router.invoke({\"question\": state[\"question\"]})\n",
    "\n",
    "    if router[\"result\"]:\n",
    "        return \"continue\"\n",
    "    else:\n",
    "        return \"fallback\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.load import dumps, loads\n",
    "\n",
    "def reciprocal_rank_fusion(results: list[list], k=60):\n",
    "    \"\"\" Reciprocal_rank_fusion that takes multiple lists of ranked documents \n",
    "        and an optional parameter k used in the RRF formula \"\"\"\n",
    "    \n",
    "    # Initialize a dictionary to hold fused scores for each unique document\n",
    "    fused_scores = {}\n",
    "\n",
    "    # Iterate through each list of ranked documents\n",
    "    for docs in results:\n",
    "        # Iterate through each document in the list, with its rank (position in the list)\n",
    "        for rank, doc in enumerate(docs):\n",
    "            # Convert the document to a string format to use as a key (assumes documents can be serialized to JSON)\n",
    "            doc_str = dumps(doc)\n",
    "            # If the document is not yet in the fused_scores dictionary, add it with an initial score of 0\n",
    "            if doc_str not in fused_scores:\n",
    "                fused_scores[doc_str] = 0\n",
    "            # Retrieve the current score of the document, if any\n",
    "            previous_score = fused_scores[doc_str]\n",
    "            # Update the score of the document using the RRF formula: 1 / (rank + k)\n",
    "            fused_scores[doc_str] += 1 / (rank + k)\n",
    "\n",
    "    # Sort the documents based on their fused scores in descending order to get the final reranked results\n",
    "    reranked_results = [\n",
    "        (loads(doc), score)\n",
    "        for doc, score in sorted(fused_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    ]\n",
    "\n",
    "    # Return the reranked results as a list of tuples, each containing the document and its fused score\n",
    "    return reranked_results\n",
    "\n",
    "# retriever_cc.map().invoke({\"question\": \"Quais os produtos da Brick?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Retriever node\n",
    "\n",
    "def civil_code_retriever_node(state):\n",
    "    # RAG-Fusion template\n",
    "    print(\"civil_code_retriever_node\")\n",
    "\n",
    "    question = state[\"question\"]\n",
    "\n",
    "    civil_code_rag_fusion_template = \"\"\"You are a helpful assistant that generates multiple search queries based on a single input query. \\n\n",
    "    You work for a company called Brick Seguros - it helps fleet operators to manage their risks.\n",
    "    Generate multiple search queries related to: {question} \\n\n",
    "    Remember to be concise and clear. Be direct and to the point. \\n\n",
    "    Remember that they should be related to Brazilian civil code.\n",
    "    Output (3 queries):\"\"\"\n",
    "    civil_code_prompt_rag_fusion = ChatPromptTemplate.from_template(civil_code_rag_fusion_template)\n",
    "\n",
    "    custom_parser = StrOutputParser() | (lambda x: x.split(\"\\n\"))\n",
    "\n",
    "    civil_code_generate_queries = (\n",
    "        civil_code_prompt_rag_fusion \n",
    "        | light_model\n",
    "        | custom_parser ### This is a custom function that splits the output by new lines\n",
    "    )\n",
    "\n",
    "    civil_code_chain_rag_fusion = civil_code_generate_queries | retriever_cc.map() | reciprocal_rank_fusion\n",
    "\n",
    "    ranked_docs = civil_code_chain_rag_fusion.invoke({\"question\": question})\n",
    "\n",
    "    return {\"documents\": ranked_docs, \"question\": question}\n",
    "\n",
    "### Doc grader node\n",
    "\n",
    "def civil_code_document_grader(state):\n",
    "    \"\"\"\n",
    "    Determines whether the retrieved documents are relevant to the question\n",
    "    If any document is not relevant, we will set a flag to run web search\n",
    "    Returns Filtered out irrelevant documents and updated web_search state\n",
    "    \"\"\"\n",
    "    \n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", \"\"\"\n",
    "                You are a grader assessing relevance of a retrieved document to a user question. \\n\n",
    "                If the document contains keywords related to the user question, grade it as relevant. \\n\n",
    "                It does not need to be a stringent test. The goal is to filter out erroneous retrievals. \\n\n",
    "                Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question. \\n\n",
    "                Provide the binary score as a JSON with a single key 'score' and no premable or explaination.\n",
    "            \"\"\"),\n",
    "            (\"user\", \"\"\"\n",
    "                Here is the retrieved document: \\n\\n {document} \\n\\n\n",
    "                Here is the user question: {question}\n",
    "            \"\"\")\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    parser = JsonOutputParser()\n",
    "\n",
    "    chain = (\n",
    "        prompt\n",
    "        | light_model\n",
    "        | parser\n",
    "    )\n",
    "\n",
    "    # Score each doc\n",
    "    filtered_docs = []\n",
    "    web_search = False\n",
    "    for d in documents:\n",
    "        score = chain.invoke({\"question\": question, \"document\": d[0].page_content})\n",
    "        grade = score['score']\n",
    "        # Document relevant\n",
    "        \n",
    "        if grade.lower() == \"yes\":\n",
    "            filtered_docs.append(d)\n",
    "\n",
    "        # Document not relevant\n",
    "        else:\n",
    "            # We do not include the document in filtered_docs\n",
    "            # We set a flag to indicate that we want to run web search\n",
    "            web_search = True\n",
    "            continue\n",
    "    \n",
    "    return {\"documents\": filtered_docs, \"question\": question, \"web_search\": web_search}\n",
    "\n",
    "\n",
    "def decide_to_generate(state):\n",
    "    \"\"\"\n",
    "    Determines whether to generate an answer, or add web search\n",
    "    \"\"\"\n",
    "    if state[\"web_search\"] == True:\n",
    "        return \"websearch\"\n",
    "    else:\n",
    "        return \"generate\"\n",
    "    \n",
    "    \n",
    "docs = civil_code_retriever_node(CivilCodeSearchGraphState(question=\"O que  o cdigo civil brasileiro?\"))\n",
    "docs = civil_code_retriever_node(CivilCodeSearchGraphState(question=\"De quem  a responsabilidade em uma coliso de veculos?\"))\n",
    "print(docs)\n",
    "grader_docs = civil_code_document_grader(CivilCodeSearchGraphState(docs))\n",
    "grader_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Search\n",
    "# from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "def civil_code_web_search(state):\n",
    "    \"\"\"\n",
    "    Web search based based on the question. Appended web results to documents\n",
    "    \"\"\"\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    ##### TO DO: Implement web search here #####\n",
    "    # web_search_tool = TavilySearchResults(k=3)\n",
    "\n",
    "    return {\"documents\": documents, \"question\": question, \"web_search\": False}\n",
    "\n",
    "## Generation\n",
    "def civil_code_generation(state):\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    \n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", \"\"\"\n",
    "                You are an assistant for question-answering tasks. \n",
    "                Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. \n",
    "                Use three sentences maximum and keep the answer concise\n",
    "            \"\"\"),\n",
    "            (\"user\", \"\"\"\n",
    "                Question: {question} \n",
    "                Context: {context} \n",
    "                Answer:\n",
    "            \"\"\")\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Chain\n",
    "    rag_chain = prompt | light_model | StrOutputParser()\n",
    "\n",
    "    # RAG generation\n",
    "    generation = rag_chain.invoke({\"context\": documents, \"question\": question})\n",
    "    return {\"documents\": documents, \"question\": question, \"generation\": generation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Building the grader \n",
    "def grade_generation_v_documents_and_question(state):\n",
    "    \"\"\"\n",
    "    Determines whether the generation is grounded in the document and answers question.\n",
    "    \"\"\"\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    generation = state[\"generation\"]\n",
    "    \n",
    "    hallucination_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", \"\"\"\n",
    "                You are a grader assessing whether an answer is grounded in a set of facts. \n",
    "                Give a binary score 'yes' or 'no' score to indicate whether the answer is grounded in a set of facts. \n",
    "                Provide the binary score as a JSON with a single key 'score' and no preamble or explanation.\n",
    "            \"\"\"),\n",
    "            (\"user\", \"\"\"\n",
    "                Here are the facts:\n",
    "                \\n ------- \\n\n",
    "                {documents} \n",
    "                \\n ------- \\n\n",
    "                Here is the answer: {generation}\n",
    "            \"\"\")\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    hallucination_grader = hallucination_prompt | light_model | JsonOutputParser() \n",
    "\n",
    "    answer_grader_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", \"\"\"\n",
    "                You are a grader assessing whether an answer is useful to resolve a question. \n",
    "                Give a binary score 'yes' or 'no' score to indicate whether the answer is useful to resolve a question. \n",
    "                Provide the binary score as a JSON with a single key 'score' and no preamble or explanation.\n",
    "            \"\"\"),\n",
    "            (\"user\", \"\"\"\n",
    "                Here is the answer:\n",
    "                \\n ------- \\n\n",
    "                {generation} \n",
    "                \\n ------- \\n\n",
    "                Here is the question: {question}\n",
    "            \"\"\")\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    answer_grader = answer_grader_prompt | light_model | JsonOutputParser()\n",
    "\n",
    "    score = hallucination_grader.invoke({\"documents\": documents, \"generation\": generation})\n",
    "    grade = score['score']\n",
    "\n",
    "    # Check hallucination\n",
    "    if grade == \"yes\":\n",
    "        # Check question-answering\n",
    "        score = answer_grader.invoke({\"question\": question,\"generation\": generation})\n",
    "        grade = score['score']\n",
    "        if grade == \"yes\":\n",
    "            return \"useful\"\n",
    "        else:\n",
    "            return \"not useful\"\n",
    "    else:\n",
    "        return \"not supported\"\n",
    "\n",
    "\n",
    "# docs = civil_code_retriever_node(CivilCodeSearchGraphState(question=\"O que  o cdigo civil brasileiro?\"))\n",
    "# docs = civil_code_retriever_node(CivilCodeSearchGraphState(question=\"De quem  a responsabilidade em uma coliso de veculos?\"))\n",
    "# print(docs)\n",
    "# grader_docs = civil_code_document_grader(docs)\n",
    "# grade_generation_v_documents_and_question(civil_code_generation(grader_docs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "### Defining the graph\n",
    "\n",
    "\n",
    "from langgraph.graph import END, StateGraph\n",
    "\n",
    "civil_code_graph = StateGraph(CivilCodeSearchGraphState)\n",
    "\n",
    "civil_code_graph.add_node(\"civil_code_retriever_node\", civil_code_retriever_node)\n",
    "civil_code_graph.add_node(\"civil_code_document_grader\", civil_code_document_grader)\n",
    "civil_code_graph.add_node(\"civil_code_generation\", civil_code_generation)\n",
    "civil_code_graph.add_node(\"civil_code_web_search\", civil_code_web_search)\n",
    "\n",
    "civil_code_graph.add_edge(\"civil_code_retriever_node\", \"civil_code_document_grader\")\n",
    "civil_code_graph.add_edge(\"civil_code_web_search\", \"civil_code_generation\")\n",
    "\n",
    "civil_code_graph.add_conditional_edges(\"civil_code_document_grader\", decide_to_generate, {\"generate\": \"civil_code_generation\", \"websearch\": \"civil_code_web_search\"})\n",
    "civil_code_graph.add_conditional_edges(\"civil_code_generation\", grade_generation_v_documents_and_question, {\"useful\": END, \"not useful\": \"civil_code_web_search\", \"not supported\": \"civil_code_generation\"})\n",
    "\n",
    "civil_code_graph.set_conditional_entry_point(\n",
    "    civil_code_routing_node, \n",
    "    {\n",
    "        \"continue\": \"civil_code_retriever_node\",\n",
    "        \"fallback\": \"civil_code_web_search\"\n",
    "    }\n",
    ")\n",
    "\n",
    "civil_code_graph_runnable = civil_code_graph.compile()\n",
    "\n",
    "# Image(civil_code_graph_runnable.get_graph().draw_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Creating the tool\n",
    "\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def civil_code_tool(\n",
    "    question: str\n",
    "):\n",
    "    \"\"\"\n",
    "        This tool retrieves answers for a questions about Brazilian Civil Code.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        return civil_code_graph_runnable.invoke({\"question\": question, \"web_search\": False})\n",
    "    except Exception as error:\n",
    "        return str(error)\n",
    "\n",
    "civil_code_tool(\"Quais os direitos do consumidor?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Database Query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RAG with different Indexing and Query Construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./assets/rag-schema.jpeg\" alt=\"drawing\" style=\"width:800px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./assets/sql.jpeg\" alt=\"drawing\" style=\"width:800px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Claims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from typing import Optional, List, TypedDict\n",
    "insured_vehicles={\n",
    "   'ABL6I88':{'doc':'12345678912','covergaes':['THEFT','CRASH']},\n",
    "   'RHV1C98':{'doc':'73658918371','covergaes':['THIRD_PARTY_DAMAGE','THIRD_PARTY_INJURY']},\n",
    "   'GCC7J84':{'doc':'99888473655563','covergaes':['THIRD_PARTY_DAMAGE','THIRD_PARTY_INJURY']},\n",
    "   'ACS4D96':{'doc':'43667636000102','covergaes':['THEFT','CRASH','THIRD_PARTY_DAMAGE','THIRD_PARTY_INJURY']},\n",
    "   'ACS3H04':{'doc':'43667636000102','covergaes':['THEFT','CRASH','THIRD_PARTY_DAMAGE','THIRD_PARTY_INJURY']}\n",
    "}\n",
    "class CreatClaimGraphResult(BaseModel):\n",
    "   claim_id: str\n",
    "   claim_due_days: int\n",
    "class CreateClaimGraphState(TypedDict):\n",
    "   # Input\n",
    "   plate: str\n",
    "   document: str\n",
    "   claim_type: str\n",
    "   claim_address: str\n",
    "   claim_description: str\n",
    "   claim_date: str\n",
    "   # Internal\n",
    "   tries: Optional[int] = 0\n",
    "   errors: List[str] = []\n",
    "   # Output\n",
    "   result: Optional[CreatClaimGraphResult] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verification functions\n",
    "import re\n",
    "from langgraph.graph import END, StateGraph\n",
    "from datetime import datetime,timedelta\n",
    "from PIL import Image\n",
    "date_re=re.compile(r'\\d{4}-\\d{2}-\\d{2}')\n",
    "claims=[]\n",
    "## INPUTS\n",
    "def verify_input(state):\n",
    "    if not state['plate']:\n",
    "        state['errors'].append('Plate is required')\n",
    "    else:\n",
    "        state['plate']=state['plate'].upper().replace('-','').replace(' ','')\n",
    "    if not state['document']:\n",
    "        state['errors'].append('document is required')\n",
    "    else:\n",
    "        state['document']=state['document'].replace('.','').replace('-','').replace('/','').replace(' ','')\n",
    "    if not state['claim_type']:\n",
    "        state['errors'].append('Claim Type is required')\n",
    "    if state['claim_type'] not in ['THEFT','CRASH','THIRD_PARTY_DAMAGE','THIRD_PARTY_INJURY']:\n",
    "        state['errors'].append('Claim Type must be one of THEFT, CRASH, THIRD_PARTY_DAMAGE, THIRD_PARTY_INJURY')\n",
    "    if not state['claim_address']:\n",
    "        state['errors'].append('Claim Address is required')\n",
    "    if not state['claim_description']:\n",
    "        state['errors'].append('Claim Description is required')\n",
    "    if not state['claim_date']:\n",
    "        state['errors'].append('Claim Date is required')\n",
    "    if not date_re.match(state['claim_date']):\n",
    "        state['errors'].append('Claim Date must be in the format YYYY-MM-DD')\n",
    "    return state\n",
    "def has_input_errors(state):\n",
    "    if(len(state.get(\"errors\")) > 0):\n",
    "        return \"end\"\n",
    "    else:\n",
    "        return \"continue\"\n",
    "## Coverages\n",
    "def verify_vehicle_and_coverage(state):\n",
    "    if state['plate'] not in insured_vehicles:\n",
    "        state['errors'].append('Vehicle not insured')\n",
    "        return state\n",
    "    if insured_vehicles[state['plate']]['doc']!=state['document']:\n",
    "        state['errors'].append('Document does not match vehicle')\n",
    "    if state['claim_type'] not in insured_vehicles[state['plate']]['covergaes']:\n",
    "        state['errors'].append('Claim Type not covered')\n",
    "    return state\n",
    "def has_vehicle_errors(state):\n",
    "    if(len(state.get(\"errors\")) > 0):\n",
    "        return \"end\"\n",
    "    else:\n",
    "        return \"continue\"\n",
    "## Claim\n",
    "def create_claim(state):\n",
    "    if state['claim_type']=='THEFT':\n",
    "        days=45\n",
    "    elif state['claim_type']=='CRASH':\n",
    "        days=30\n",
    "    else:\n",
    "        days=20\n",
    "    state['result']=CreatClaimGraphResult(claim_id='2024'+str(uuid.uuid4().int)[:13],claim_due_days=days)\n",
    "    claims.append(\n",
    "        {\n",
    "            'claim_id':state['result'].claim_id,\n",
    "            'plate':state['plate'],\n",
    "            'document':state['document'],\n",
    "            'claim_type':state['claim_type'],\n",
    "            'claim_address':state['claim_address'],\n",
    "            'claim_description':state['claim_description'],\n",
    "            'claim_date':state['claim_date'],\n",
    "            'claim_due':datetime.now() + timedelta(days=days),\n",
    "            'claim_status':'OPENED'\n",
    "        }\n",
    "    )\n",
    "    return state\n",
    "#define graph\n",
    "create_claim_graph = StateGraph(CreateClaimGraphState)\n",
    "create_claim_graph.add_node(\"verify_input\", verify_input)\n",
    "create_claim_graph.add_node(\"verify_vehicle_coverage\", verify_vehicle_and_coverage)\n",
    "create_claim_graph.add_node(\"create_claim\", create_claim)\n",
    "create_claim_graph.add_conditional_edges(\"verify_input\", has_input_errors, {\n",
    "    \"end\": END,\n",
    "    \"continue\": \"verify_vehicle_coverage\"\n",
    "})\n",
    "create_claim_graph.add_conditional_edges(\"verify_vehicle_coverage\", has_vehicle_errors, {\n",
    "    \"end\": END,\n",
    "    \"continue\": \"create_claim\"\n",
    "})\n",
    "create_claim_graph.set_entry_point(\"verify_input\")\n",
    "create_claim_graph.add_edge(\"create_claim\", END)\n",
    "create_claim_graph_runnable = create_claim_graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CREATE THE TOOL\n",
    "from enum import Enum\n",
    "class EntityTypeEnum(str, Enum):\n",
    "    THEFT = 'THEFT'\n",
    "    CRASH = 'CRASH'\n",
    "    THIRD_PARTY_DAMAGE = 'THIRD_PARTY_DAMAGE'\n",
    "    THIRD_PARTY_INJURY = 'THIRD_PARTY_INJURY'\n",
    "\n",
    "@tool\n",
    "def create_claim_tool(\n",
    "   plate: str,\n",
    "   document: str,\n",
    "   claim_type: EntityTypeEnum,\n",
    "   claim_address: str,\n",
    "   claim_description: str,\n",
    "   claim_date: str\n",
    "):\n",
    "    \"\"\"\n",
    "        This tool creates a claim.\n",
    "        If you do not receive one of the required parameters, you must ask for it.\n",
    "        If you can infer the claim type from description, use it\n",
    "        Claims types must be one of THEFT, CRASH, THIRD_PARTY_DAMAGE, THIRD_PARTY_INJURY\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return create_claim_graph_runnable.invoke({\n",
    "            'plate': plate,\n",
    "            'document': document,\n",
    "            'claim_type': claim_type,\n",
    "            'claim_address': claim_address,\n",
    "            'claim_description': claim_description,\n",
    "            'claim_date': claim_date,\n",
    "            \"tries\": 0,\n",
    "            'errors':[]\n",
    "        })\n",
    "    except Exception as error:\n",
    "        return str(error)\n",
    "\n",
    "@tool\n",
    "def verify_claim_status(\n",
    "   query_value: str,\n",
    "   query_key: str,\n",
    "):\n",
    "    \"\"\"\n",
    "        This tool verifies the status of a claim.\n",
    "        the supported values for query_key are: 'claim_id', 'plate', 'document'\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if query_key not in ['claim_id','plate','document']:\n",
    "            return 'Invalid query key'\n",
    "        for item in claims:\n",
    "            if item[query_key]==query_value:\n",
    "                return item\n",
    "        return 'Cliam not found'\n",
    "    except Exception as error:\n",
    "        return str(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing the Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain.agents.structured_chat.base.StructuredChatAgent` was deprecated in langchain 0.1.0 and will be removed in 0.2.0. Use create_structured_chat_agent instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from langchain.callbacks.base import BaseCallbackHandler\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.agents import AgentExecutor, load_tools, StructuredChatAgent\n",
    "\n",
    "loaded_tools = load_tools([\"wikipedia\", \"serpapi\", \"llm-math\"], from_llm=light_model, llm=light_model)\n",
    "tools = [\n",
    "    loaded_tools[0],\n",
    "    loaded_tools[1],\n",
    "    loaded_tools[2],\n",
    "    read_txt_file,\n",
    "    read_docx_file,\n",
    "    read_pdf_file,\n",
    "    read_md_file,\n",
    "    read_html_file,\n",
    "    read_json_file,\n",
    "    # plot_bar_chart,\n",
    "    # plot_line_chart,\n",
    "    # brick_internal_rag_tool,\n",
    "    # insurance_question_tool,\n",
    "    # civil_code_tool\n",
    "    # create_claim_tool,\n",
    "    # verify_claim_status\n",
    "]\n",
    "\n",
    "prefix = \"\"\"\n",
    "Your name is Toninho.\n",
    "You work for a company called Brick Seguros - it helps fleet operators to manage thir risks.\n",
    "You are a customer support agent. \n",
    "You are here to help the user with his questions.\n",
    "You are an expert in the field of fleets and drivers onboarding.\n",
    "Have a conversation with a human answering his questions as best you can. \n",
    "Keep him engaged and interested in the conversation.\n",
    "Start by introducing yourself and ask the user for his questions.\n",
    "Be polite and professional. Always try to be helpful.\n",
    "You are allowed to ask questions if you need more information.\n",
    "Always analyze the result of the tools you use.\n",
    "If you don't know a variable needed for a tool, ask the user.\n",
    "\"\"\"\n",
    "\n",
    "suffix = \"\"\"\n",
    "Action Input can be nullable eventually.\n",
    "Begin!\"\n",
    "\n",
    "{chat_history}\n",
    "Question: {input}\n",
    "{agent_scratchpad}\"\"\"\n",
    "\n",
    "prompt = StructuredChatAgent.create_prompt(\n",
    "    tools,\n",
    "    prefix=prefix,\n",
    "    suffix=suffix,\n",
    "    input_variables=[\"input\", \"chat_history\", \"agent_scratchpad\"],   \n",
    ")\n",
    "\n",
    "llm_base_chain = LLMChain(llm=powerful_model, prompt=prompt)\n",
    "\n",
    "agent = StructuredChatAgent(llm_chain=llm_base_chain, tools=tools, verbose=True)\n",
    "\n",
    "agent_executor = AgentExecutor.from_agent_and_tools(\n",
    "    agent=agent, \n",
    "    tools=tools, \n",
    "    verbose=True, \n",
    "    memory=chat_history,\n",
    "    handle_parsing_errors=True,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from '/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/wikipedia/__init__.py'>, top_k_results=3, lang='en', load_all_available_meta=False, doc_content_chars_max=4000)),\n",
       " Tool(name='Search', description='A search engine. Useful for when you need to answer questions about current events. Input should be a search query.', func=<bound method SerpAPIWrapper.run of SerpAPIWrapper(search_engine=<class 'serpapi.google_search.GoogleSearch'>, params={'engine': 'google', 'google_domain': 'google.com', 'gl': 'us', 'hl': 'en'}, serpapi_api_key='945c0fb7d5eccde352ecffdaf8e152cd51ee22ae2b6ff92dba194dbb3a855378', aiosession=None)>, coroutine=<bound method SerpAPIWrapper.arun of SerpAPIWrapper(search_engine=<class 'serpapi.google_search.GoogleSearch'>, params={'engine': 'google', 'google_domain': 'google.com', 'gl': 'us', 'hl': 'en'}, serpapi_api_key='945c0fb7d5eccde352ecffdaf8e152cd51ee22ae2b6ff92dba194dbb3a855378', aiosession=None)>),\n",
       " Tool(name='Calculator', description='Useful for when you need to answer questions about math.', func=<bound method Chain.run of LLMMathChain(llm_chain=LLMChain(prompt=PromptTemplate(input_variables=['question'], template='Translate a math problem into a expression that can be executed using Python\\'s numexpr library. Use the output of running this code to answer the question.\\n\\nQuestion: ${{Question with math problem.}}\\n```text\\n${{single line mathematical expression that solves the problem}}\\n```\\n...numexpr.evaluate(text)...\\n```output\\n${{Output of running the code}}\\n```\\nAnswer: ${{Answer}}\\n\\nBegin.\\n\\nQuestion: What is 37593 * 67?\\n```text\\n37593 * 67\\n```\\n...numexpr.evaluate(\"37593 * 67\")...\\n```output\\n2518731\\n```\\nAnswer: 2518731\\n\\nQuestion: 37593^(1/5)\\n```text\\n37593**(1/5)\\n```\\n...numexpr.evaluate(\"37593**(1/5)\")...\\n```output\\n8.222831614237718\\n```\\nAnswer: 8.222831614237718\\n\\nQuestion: {question}\\n'), llm=ChatOpenAI(verbose=True, client=<openai.resources.chat.completions.Completions object at 0x15e24cc50>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x15e84d550>, temperature=0.0, openai_api_key=SecretStr('**********'), openai_proxy='')))>, coroutine=<bound method Chain.arun of LLMMathChain(llm_chain=LLMChain(prompt=PromptTemplate(input_variables=['question'], template='Translate a math problem into a expression that can be executed using Python\\'s numexpr library. Use the output of running this code to answer the question.\\n\\nQuestion: ${{Question with math problem.}}\\n```text\\n${{single line mathematical expression that solves the problem}}\\n```\\n...numexpr.evaluate(text)...\\n```output\\n${{Output of running the code}}\\n```\\nAnswer: ${{Answer}}\\n\\nBegin.\\n\\nQuestion: What is 37593 * 67?\\n```text\\n37593 * 67\\n```\\n...numexpr.evaluate(\"37593 * 67\")...\\n```output\\n2518731\\n```\\nAnswer: 2518731\\n\\nQuestion: 37593^(1/5)\\n```text\\n37593**(1/5)\\n```\\n...numexpr.evaluate(\"37593**(1/5)\")...\\n```output\\n8.222831614237718\\n```\\nAnswer: 8.222831614237718\\n\\nQuestion: {question}\\n'), llm=ChatOpenAI(verbose=True, client=<openai.resources.chat.completions.Completions object at 0x15e24cc50>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x15e84d550>, temperature=0.0, openai_api_key=SecretStr('**********'), openai_proxy='')))>),\n",
       " StructuredTool(name='read_txt_file', description='read_txt_file(file: str) - This tool reads a text file and returns its content.\\n        It receives the file path as input.', args_schema=<class 'pydantic.v1.main.read_txt_fileSchema'>, func=<function read_txt_file at 0x13f29b6a0>),\n",
       " StructuredTool(name='read_docx_file', description='read_docx_file(file) - This tool reads a docx file and returns its content.\\n        It receives the file path as input.', args_schema=<class 'pydantic.v1.main.read_docx_fileSchema'>, func=<function read_docx_file at 0x13f29b060>),\n",
       " StructuredTool(name='read_pdf_file', description='read_pdf_file(file) - This tool reads a pdf file and returns its content.\\n        It receives the file path as input.', args_schema=<class 'pydantic.v1.main.read_pdf_fileSchema'>, func=<function read_pdf_file at 0x13f29b100>),\n",
       " StructuredTool(name='read_md_file', description='read_md_file(file) - This tool reads a markdown file and returns its content.\\n        It receives the file path as input.', args_schema=<class 'pydantic.v1.main.read_md_fileSchema'>, func=<function read_md_file at 0x16a02a020>),\n",
       " StructuredTool(name='read_html_file', description='read_html_file(file) - This tool reads a html file and returns its content.\\n        It receives the file path as input.', args_schema=<class 'pydantic.v1.main.read_html_fileSchema'>, func=<function read_html_file at 0x16a02aac0>),\n",
       " StructuredTool(name='read_json_file', description='read_json_file(file) - This tool reads a json file and returns its content.\\n        It receives the file path as input.', args_schema=<class 'pydantic.v1.main.read_json_fileSchema'>, func=<function read_json_file at 0x16a02a200>)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.llm_chain.prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SYSTEM PROMPT**\n",
    "\n",
    "Your name is Toninho.\n",
    "\n",
    "You work for a company called Brick Seguros - it helps fleet operators to manage thir risks. \n",
    "\n",
    "You are a customer support agent. \n",
    "\n",
    "You are here to help the user with his questions.\n",
    "\n",
    "You are an expert in the field of fleets and drivers onboarding.\n",
    "\n",
    "Have a conversation with a human answering his questions as best you can. \n",
    "\n",
    "Keep him engaged and interested in the conversation.\n",
    "\n",
    "Start by introducing yourself and ask the user for his questions.\n",
    "\n",
    "Be polite and professional. Always try to be helpful.\n",
    "\n",
    "You are allowed to ask questions if you need more information.\n",
    "Always analyze the result of the tools you use.\n",
    "If you don\\'t know a variable needed for a tool, ask the user.\n",
    "\n",
    "\n",
    "Use a json blob to specify a tool by providing an action key (tool name) and an action_input key (tool input).\n",
    "\n",
    "Valid \"action\" values: \"Final Answer\" or \n",
    "\n",
    "Provide only ONE action per $JSON_BLOB, as shown:\n",
    "\n",
    "```\n",
    "{{\n",
    "    \"action\": $TOOL_NAME,\n",
    "    \"action_input\": $INPUT\n",
    "}}\n",
    "```\n",
    "\n",
    "Follow this format:\n",
    "\n",
    "Question: input question to answer\n",
    "Thought: consider previous and subsequent steps\n",
    "Action:\n",
    "```\n",
    "$JSON_BLOB\n",
    "```\n",
    "Observation: action result\n",
    "... (repeat Thought/Action/Observation N times)\n",
    "Thought: I know what to respond\n",
    "Action:\n",
    "```\n",
    "{{\n",
    "    \"action\": \"Final Answer\",\n",
    "    \"action_input\": \"Final response to human\"\n",
    "}}\n",
    "```\n",
    "\n",
    "\n",
    "Action Input can be nullable eventually.\n",
    "Begin!\"\n",
    "\n",
    "{chat_history}\n",
    "\n",
    "Question: {input}\n",
    "\n",
    "{agent_scratchpad}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating our Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "def translate_to_portuguese(text):\n",
    "    \"\"\"This function translates a text to portuguese\"\"\"\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "       (\"user\", \"\"\"\n",
    "            Traduza o seguinte texto para o portugus:{text}.\n",
    "            No de introduo e concluso.\n",
    "            Apenas retorne o texto traduzido.\n",
    "            No retorne o texot em ingls.\n",
    "            \"\"\"),\n",
    "    )\n",
    "    chain = (\n",
    "        prompt |\n",
    "        light_model\n",
    "    )\n",
    "    res = chain.invoke({\"text\": text})\n",
    "    return res\n",
    "\n",
    "class BrickAi:\n",
    "    def __init__(self, agent_executor):\n",
    "        self.agent_executor = agent_executor\n",
    "\n",
    "    def run(self, input):\n",
    "        try:\n",
    "            content = self.agent_executor.invoke(input)\n",
    "            res = translate_to_portuguese(str(content))\n",
    "            \n",
    "            return res.content\n",
    "        except Exception as error:\n",
    "            return {\"error\": str(error)}\n",
    "\n",
    "brickAi = BrickAi(agent_executor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mLuxemburgo  uma monarquia constitucional e no tem um presidente. O chefe de estado  o Gro-Duque, e o atual Gro-Duque de Luxemburgo  Henri, que assumiu o cargo em 7 de outubro de 2000. Se precisar de mais informaes ou tiver outras perguntas, estou  disposio!\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Luxemburgo  uma monarquia constitucional e no tem um presidente. O chefe de estado  o Gro-Duque, e o atual Gro-Duque de Luxemburgo  Henri, que assumiu o cargo em 7 de outubro de 2000. Se precisar de mais informaes ou tiver outras perguntas, estou  disposio!'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# brickAi.run(\"Oi\")\n",
    "\n",
    "# brickAi.run('Quem foi Julio Cesar?')\n",
    "\n",
    "brickAi.run(\"Qual o presidente de Luxemburgo?\")\n",
    "\n",
    "\n",
    "# light_model.invoke(\"Qual a tanh de 0.3543?\")\n",
    "# brickAi.run(\"Qual a tanh de 0.3543?\") ### 0.34018347444084"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mVou verificar o contedo do arquivo `./files/inputs.txt` para voc. Um momento, por favor.\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"action\": \"read_txt_file\",\n",
      "  \"action_input\": {\n",
      "    \"file\": \"./files/inputs.txt\"\n",
      "  }\n",
      "}\n",
      "```\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m{'content': '\\nLocadora XPTY - Forms\\n\\nFormulrio para Cadastro de motoristas do vendedor Guilherme \\n\\nCor: #00FF00\\nEntidade: PF', 'error': None, 'file': './files/inputs.txt'}\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mO arquivo `./files/inputs.txt` contm informaes relacionadas a um formulrio de cadastro de motoristas para a Locadora XPTY. Aqui esto os detalhes presentes no arquivo:\n",
      "\n",
      "- **Nome da Locadora:** Locadora XPTY - Forms\n",
      "- **Descrio:** Formulrio para Cadastro de motoristas do vendedor Guilherme\n",
      "- **Cor:** #00FF00\n",
      "- **Entidade:** Pessoa Fsica (PF)\n",
      "\n",
      "Se precisar de mais informaes ou tiver outras perguntas, estou  disposio para ajudar!\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'O arquivo `./files/inputs.txt` contm informaes relacionadas a um formulrio de cadastro de motoristas para a Locadora XPTY. Aqui esto os detalhes presentes no arquivo:\\n\\n- **Nome da Locadora:** Locadora XPTY - Forms\\n- **Descrio:** Formulrio para Cadastro de motoristas do vendedor Guilherme\\n- **Cor:** #00FF00\\n- **Entidade:** Pessoa Fsica (PF)'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# brickAi.run(\"Qual o contedo do arquivo ./inputs.txt\")\n",
    "brickAi.run(\"Qual o contedo do arquivo ./files/inputs.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# brickAi.run(\"Gere um grfico de barras dos preos dos carros do arquivo ./files/plates.json\")\n",
    "brickAi.run(\"Gere um grfico de linhas dos preos dos carros do arquivo ./files/plates.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Attention is all you need - https://arxiv.org/pdf/1706.03762.pdf\n",
    "\n",
    "RAG Fusion - https://towardsdatascience.com/forget-rag-the-future-is-rag-fusion-1147298d8ad1\n",
    "\n",
    "Adaptative RAG - https://arxiv.org/abs/2403.14403\n",
    "\n",
    "Corrective RAG - https://arxiv.org/pdf/2401.15884.pdf\n",
    "\n",
    "Self RAG - https://arxiv.org/abs/2310.11511\n",
    "\n",
    "RAG From Scratch - https://github.com/langchain-ai/rag-from-scratch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
